{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "from sage.utils import evaluate_sigmoid\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.models import ResNetv2,ResBlockv2\n",
    "\n",
    "hyperparameters = {\n",
    "    'block':ResBlockv2,\n",
    "    'widthi':[4],\n",
    "    'depthi':[1],\n",
    "    'n_output_neurons':1,\n",
    "    'norm':'layer'\n",
    "}\n",
    "\n",
    "model = ResNetv2(**hyperparameters)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50)\n",
    "\n",
    "trainlossi = []\n",
    "devlossi = []\n",
    "testlossi = []\n",
    "trainf1i = []\n",
    "devf1i = []\n",
    "testf1i = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_participants = ['alsaad','iftakhar']\n",
    "test_participant = f'tonmoy'\n",
    "train_files = [f'../data/alpha_pt_windowsize100/{train_participant}_{phase}.pt' for train_participant in train_participants for phase in ['phase1','phase2']]\n",
    "tts = []\n",
    "for train_file in train_files:\n",
    "    print(train_file)\n",
    "    a,b,c,d = train_test_split(*torch.load(train_file,weights_only=True),random_state=0)\n",
    "    tts.append((a[::1],b[::1],c[::1],d[::1]))\n",
    "X_train = torch.vstack([tt[0] for tt in tts])\n",
    "X_dev = torch.vstack([tt[1] for tt in tts])\n",
    "y_train = torch.vstack([tt[2] for tt in tts])\n",
    "y_dev = torch.vstack([tt[3] for tt in tts])\n",
    "print(X_train.shape,X_dev.shape,y_train.shape,y_dev.shape)\n",
    "trainloader = DataLoader(TensorDataset(X_train,y_train),batch_size=128)\n",
    "devloader = DataLoader(TensorDataset(X_dev,y_dev),batch_size=128)\n",
    "testloader = DataLoader(TensorDataset(*torch.load(f'../data/alpha_pt_windowsize100/{test_participant}_phase2.pt',weights_only=True)),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    running_loss = 0.0\n",
    "    train_preds, train_labels = [], []\n",
    "\n",
    "    for i, (Xi, yi) in enumerate(trainloader):\n",
    "        Xi, yi = Xi.to(device), yi.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(Xi)\n",
    "        loss = criterion(logits, yi)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        train_preds.extend(logits.sigmoid().round().detach().cpu().numpy())\n",
    "        train_labels.extend(yi.cpu().numpy())\n",
    "\n",
    "    trainlossi.append(running_loss / len(trainloader))\n",
    "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
    "    trainf1i.append(train_f1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loss,y_true,y_pred = evaluate_sigmoid(devloader,model,criterion)\n",
    "        devlossi.append(loss)\n",
    "        dev_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        devf1i.append(dev_f1)\n",
    "    with torch.no_grad():\n",
    "        loss,y_true,y_pred = evaluate_sigmoid(testloader,model,criterion)\n",
    "        testlossi.append(loss)\n",
    "        test_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        testf1i.append(test_f1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    ax1.plot(trainlossi)\n",
    "    ax1.plot(devlossi)\n",
    "    ax1.plot(testlossi)\n",
    "    ax2.plot(trainf1i)\n",
    "    ax2.plot(devf1i)\n",
    "    ax2.plot(testf1i)\n",
    "    plt.savefig('loss.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model':model.state_dict(),\n",
    "    'optimizer':optimizer.state_dict(),\n",
    "    'criterion':criterion.state_dict(),\n",
    "    'trainlossi':trainlossi,\n",
    "    'devlossi':devlossi,\n",
    "    'testlossi':testlossi,\n",
    "    'trainf1i':trainf1i,\n",
    "    'devf1i':devf1i,\n",
    "    'testf1i':testf1i\n",
    "}\n",
    "torch.save(config,f'../results/{\"_\".join(train_participants)}_base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,y_true,y_pred = evaluate_sigmoid(trainloader,model,criterion)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))\n",
    "loss,y_true,y_pred = evaluate_sigmoid(devloader,model,criterion)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))\n",
    "loss,y_true,y_pred = evaluate_sigmoid(testloader,model,criterion)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfs = []\n",
    "# ['alsaad','anam','asfiqur','ejaz','iftakhar','will','ashlin','tj','tonmoy']\n",
    "for p in ['alsaad','anam','asfiqur','ejaz','iftakhar','will','ashlin','tj','tonmoy']:\n",
    "    print(p)\n",
    "    for phase in [1,2]:\n",
    "        testloader = DataLoader(TensorDataset(*torch.load(f'../data/alpha_pt_windowsize100/{p}_phase{phase}.pt',weights_only=True)),batch_size=128)\n",
    "        loss,y_true,y_pred = evaluate_sigmoid(testloader,model,criterion)\n",
    "        perfs.append([f1_score(y_true,y_pred,average='macro'),p,phase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame(perfs)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df,x=1,y=0,hue=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
