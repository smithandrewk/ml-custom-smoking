{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "import os\n",
    "from lib.env import DATA_PATH\n",
    "import json\n",
    "import pandas as pd\n",
    "from lib.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader,TensorDataset,ConcatDataset\n",
    "import torch\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,classification_report\n",
    "\n",
    "FS = 50\n",
    "WINDOWSIZE = 100 * FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.models import ResNetv2,ResBlockv2\n",
    "from tqdm import tqdm\n",
    "from sage.utils import evaluate_sigmoid\n",
    "\n",
    "hyperparameters = {\n",
    "    'block':ResBlockv2,\n",
    "    'widthi':[4],\n",
    "    'depthi':[2],\n",
    "    'n_output_neurons':1,\n",
    "    'norm':'layer'\n",
    "}\n",
    "\n",
    "traindataset = ConcatDataset([\n",
    "    get_dataset_for_project(\"ejaz_phase1\",windowsize=WINDOWSIZE),\n",
    "    get_dataset_for_project(\"ejaz_phase2\",windowsize=WINDOWSIZE),\n",
    "    # get_dataset_for_project(\"iftakhar_phase1\",windowsize=WINDOWSIZE),\n",
    "    # get_dataset_for_project(\"iftakhar_phase2\",windowsize=WINDOWSIZE),\n",
    "    ])\n",
    "\n",
    "# traindataset = get_dataset_for_project(\"alsaad_phase1\",windowsize=WINDOWSIZE)\n",
    "devdataset = get_dataset_for_project(\"alsaad_phase1\",windowsize=WINDOWSIZE)\n",
    "testdataset = get_dataset_for_project(\"alsaad_phase2\",windowsize=WINDOWSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "test_f1_scores = []\n",
    "model = ResNetv2(**hyperparameters)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=3e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = DataLoader(traindataset,batch_size=128,shuffle=True)\n",
    "trainloader = DataLoader(ConcatDataset([traindataset,devdataset]),batch_size=128,shuffle=True)\n",
    "devloader = DataLoader(devdataset,batch_size=128,shuffle=True)\n",
    "testloader = DataLoader(testdataset,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Set the interval for validation evaluation (e.g., every 10 batches)\n",
    "val_interval = 10\n",
    "\n",
    "# Move the model to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_preds, train_labels = [], []\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "        # Evaluate the validation and test sets every `val_interval` batches\n",
    "        if (i + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "\n",
    "            # Validation evaluation\n",
    "            val_loss = 0.0\n",
    "            val_preds, val_labels_list = [], []\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_labels in devloader:\n",
    "                    # Move inputs and labels to the GPU\n",
    "                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "                    \n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "                    # Store validation predictions and labels\n",
    "                    val_preds.extend(torch.sigmoid(val_outputs).round().cpu().numpy())\n",
    "                    val_labels_list.extend(val_labels.cpu().numpy())\n",
    "\n",
    "            val_loss /= len(devloader)  # Average validation loss\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Test evaluation\n",
    "            test_loss = 0.0\n",
    "            test_preds, test_labels_list = [], []\n",
    "            with torch.no_grad():\n",
    "                for test_inputs, test_labels in testloader:\n",
    "                    # Move inputs and labels to the GPU\n",
    "                    test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "                    \n",
    "                    test_outputs = model(test_inputs)\n",
    "                    test_loss += criterion(test_outputs, test_labels).item()\n",
    "\n",
    "                    # Store test predictions and labels\n",
    "                    test_preds.extend(torch.sigmoid(test_outputs).round().cpu().numpy())\n",
    "                    test_labels_list.extend(test_labels.cpu().numpy())\n",
    "\n",
    "            test_loss /= len(testloader)  # Average test loss\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "            # Compute F1 scores\n",
    "\n",
    "\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], '\n",
    "                  f'Train Loss: {running_loss / val_interval:.4f}, Val Loss: {val_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}, Train F1: {train_f1:.4f}, Val F1: {val_f1:.4f}, Test F1: {test_f1:.4f}')\n",
    "            \n",
    "            # Reset running loss and F1 calculation data\n",
    "            train_losses.append(running_loss / val_interval)\n",
    "            running_loss = 0.0\n",
    "            train_preds, train_labels = [], []  # Reset for the next round\n",
    "            \n",
    "            model.train()  # Switch back to training mode\n",
    "\n",
    "            # Plotting losses and F1 scores in subplots\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "            # Loss plot\n",
    "            ax1.plot(train_losses, label='Train Loss')\n",
    "            ax1.plot(val_losses, label='Validation Loss')\n",
    "            ax1.plot(test_losses, label='Test Loss')\n",
    "            ax1.set_xlabel('Steps (scaled by interval)')\n",
    "            ax1.set_ylabel('Loss')\n",
    "            ax1.set_title('Loss Curves')\n",
    "            ax1.legend()\n",
    "\n",
    "            # F1 Score plot\n",
    "            ax2.plot(train_f1_scores, label='Train F1 Score')\n",
    "            ax2.plot(val_f1_scores, label='Validation F1 Score')\n",
    "            ax2.plot(test_f1_scores, label='Test F1 Score')\n",
    "            ax2.set_xlabel('Steps (scaled by interval)')\n",
    "            ax2.set_ylabel('F1 Score')\n",
    "            ax2.set_title('F1 Score Curves')\n",
    "            ax2.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('training_validation_test_curves.jpg')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'custom.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,y_true,y_pred = evaluate_sigmoid(trainloader,model,criterion)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))\n",
    "loss,y_true,y_pred = evaluate_sigmoid(devloader,model,criterion)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))\n",
    "loss,y_true,y_pred = evaluate_sigmoid(testloader,model,criterion)\n",
    "ConfusionMatrixDisplay.from_predictions(y_true,y_pred)\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
